---
title: "ex3-01"
author: "Riyanshi Bohra"
format: html
editor: visual
---

# Setting up

```{r}
# Install necessary packages
if(!require(pacman))
  install.packages("pacman")

pacman::p_load(tidyverse, rpart, rpart.plot, caret, 
  lattice, FSelector, sampling, pROC, mlbench)
```

# The Zoo Dataset

```{r}
data(Zoo, package="mlbench")
head(Zoo)
```

```{r}
library(tidyverse)
as_tibble(Zoo, rownames = "animal")
```

```{r}
# Translating all TRUE/FALSE value into factors
Zoo <- Zoo |>
  mutate(across(where(is.logical), factor, levels = c(TRUE, FALSE))) |>
  mutate(across(where(is.character), factor))
```

```{r}
# Finding summary statistics
summary(Zoo)
```

# Decision Tree

```{r}
library(rpart)
```

## Default Tree

```{r}
# Craetingg Tree with default settings(uses pre-pruning)
tree_default <- Zoo |> 
  rpart(type ~ ., data = _)
tree_default
```

```{r}
# Plotting the default tree
library(rpart.plot)
rpart.plot(tree_default, extra = 2)
```

## Full Tree

```{r}
# Creating a full tree
tree_full <- Zoo |> 
  rpart(type ~ . , data = _, 
        control = rpart.control(minsplit = 2, cp = 0))
rpart.plot(tree_full, extra = 2, 
           roundint=FALSE,
            box.palette = list("Gy", "Gn", "Bu", "Bn", 
                               "Or", "Rd", "Pu")) # specify 7 colors
```

```{r}
tree_full
```

## Training Error: Default and Full Tree

```{r}
# Training error on Default tree
predict(tree_default, Zoo) |> head ()
```

```{r}
pred <- predict(tree_default, Zoo, type="class")
head(pred)
```

```{r}
# Creating a confusion table for default tree
confusion_table <- with(Zoo, table(type, pred))
confusion_table
```

```{r}
# Calculating the correct predictions
correct <- confusion_table |> diag() |> sum()
correct
```

```{r}
# Calculating the incorrect predictions
error <- confusion_table |> sum() - correct
error
```

```{r}
# Finding the accuracy for default tree
accuracy <- correct / (correct + error)
accuracy
```

```{r}
# Use a function for accuracy

accuracy <- function(truth, prediction) {
    tbl <- table(truth, prediction)
    sum(diag(tbl))/sum(tbl)
}

accuracy(Zoo |> pull(type), pred)
```

```{r}
# Training error of the full tree

accuracy(Zoo |> pull(type), 
         predict(tree_full, Zoo, type = "class"))
```

```{r}
# Get a confusion table using caret
library(caret)
confusionMatrix(data = pred, 
                reference = Zoo |> pull(type))
```

## Make Predictions for New Data

```{r}
# Make up a new animal: A lion with feathered wings

my_animal <- tibble(hair = TRUE, feathers = TRUE, eggs = FALSE,
  milk = TRUE, airborne = TRUE, aquatic = FALSE, predator = TRUE,
  toothed = TRUE, backbone = TRUE, breathes = TRUE, venomous = FALSE,
  fins = FALSE, legs = 4, tail = TRUE, domestic = FALSE,
  catsize = FALSE, type = NA)
```

```{r}
# Fix columns to be factors like in the training set

my_animal <- my_animal |> 
  mutate(across(where(is.logical), factor, levels = c(TRUE, FALSE)))
my_animal
```

```{r}
# Make a prediction using the default tree

predict(tree_default , my_animal, type = "class")
```

## Model Evaluation with Caret

```{r}
library(caret)
```

```{r}
set.seed(2000)
```

## Creation of Train and Test data

```{r}
# Partitioning the data into 80% Train data and 20% test data
inTrain <- createDataPartition(y = Zoo$type, p = .8, list = FALSE)
Zoo_train <- Zoo |> slice(inTrain)
```

```{r}
Zoo_test <- Zoo |> slice(-inTrain)
```

## Learning a Model

```{r}
fit <- Zoo_train |>
  train(type ~ .,
    data = _ ,
    method = "rpart",
    control = rpart.control(minsplit = 2),
    trControl = trainControl(method = "cv", number = 10),
    tuneLength = 5)

fit
```

```{r}
# Plotting the model
rpart.plot(fit$finalModel, extra = 2,
  box.palette = list("Gy", "Gn", "Bu", "Bn", "Or", "Rd", "Pu"))
```

## Variable Importance

```{r}
varImp(fit)
```

```{r}
# Here is the variable importance without competing splits

imp <- varImp(fit, compete = FALSE)
imp
```

```{r}
# Plotting the variable importance
ggplot(imp)
```

## Confusion Matrix and Confidence Interval for Accuracy

```{r}
pred <- predict(fit, newdata = Zoo_test)
pred
```

```{r}
# Creating a confusion matrix
confusionMatrix(data = pred, 
                ref = Zoo_test |> pull(type))
```

# Model Comparison

```{r}
# Comparing decision trees with KNN classifier
train_index <- createFolds(Zoo_train$type, k = 10)
```

```{r}
#Building the decision tree model
rpartFit <- Zoo_train |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        tuneLength = 10,
        trControl = trainControl(method = "cv", indexOut = train_index)
  )
```

```{r}
# Building the KNN  model

knnFit <- Zoo_train |> 
  train(type ~ .,
        data = _,
        method = "knn",
        preProcess = "scale",
          tuneLength = 10,
          trControl = trainControl(method = "cv", indexOut = train_index)
  )
```

```{r}
# Compare accuracy over all folds

resamps <- resamples(list(
        CART = rpartFit,
        kNearestNeighbors = knnFit
        ))

summary(resamps)
```

```{r}
# Visualization using lattice
library(lattice)
bwplot(resamps, layout = c(3, 1))
```

```{r}
# Finding the difference in accuracy
difs <- diff(resamps)
difs
```

```{r}
summary(difs)
```

# Feature Selection and Feature Preparation

```{r}
library(FSelector)
```

## Univariate Feature Importance Score

```{r}
weights <- Zoo_train |> 
  chi.squared(type ~ ., data = _) |>
  as_tibble(rownames = "feature") |>
  arrange(desc(attr_importance))

weights
```

```{r}
# Plotting the feature importance score
ggplot(weights,
  aes(x = attr_importance, y = reorder(feature, attr_importance))) +
  geom_bar(stat = "identity") +
  xlab("Importance score") + 
  ylab("Feature")
```

```{r}
# Getting the best 5 features
subset <- cutoff.k(weights |> 
                   column_to_rownames("feature"), 5)
subset
```

```{r}
# Using only the best 5 features to build a model
f <- as.simple.formula(subset, "type")
f
```

```{r}
m <- Zoo_train |> rpart(f, data = _)
rpart.plot(m, extra = 2, roundint = FALSE)
```

```{r}
# Finding the gain ratio to calculate univariate importance scores
Zoo_train |> 
  gain.ratio(type ~ ., data = _) |>
  as_tibble(rownames = "feature") |>
  arrange(desc(attr_importance))
```

## Feature Subset Selection

```{r}
Zoo_train |> 
  cfs(type ~ ., data = _)
```

```{r}
# Defining an evaluation function
evaluator <- function(subset) {
  model <- Zoo_train |> 
    train(as.simple.formula(subset, "type"),
          data = _,
          method = "rpart",
          trControl = trainControl(method = "boot", number = 5),
          tuneLength = 0)
  results <- model$resample$Accuracy
  cat("Trying features:", paste(subset, collapse = " + "), "\n")
  m <- mean(results)
  cat("Accuracy:", round(m, 2), "\n\n")
  m
}
```

```{r}
# Starting with all features
features <- Zoo_train |> colnames() |> setdiff("type")
```

# Using Dummy variables for Factors

```{r}
tree_predator <- Zoo_train |> 
  rpart(predator ~ type, data = _)
rpart.plot(tree_predator, extra = 2, roundint = FALSE)
```

```{r}
# Convert type into a set of 0-1 dummy variables using class2ind
Zoo_train_dummy <- as_tibble(class2ind(Zoo_train$type)) |> 
  mutate(across(everything(), as.factor)) |>
  add_column(predator = Zoo_train$predator)
Zoo_train_dummy
```

```{r}
tree_predator <- Zoo_train_dummy |> 
  rpart(predator ~ ., 
        data = _,
        control = rpart.control(minsplit = 2, cp = 0.01))
rpart.plot(tree_predator, roundint = FALSE)
```

```{r}
fit <- Zoo_train |> 
  train(predator ~ type, 
        data = _, 
        method = "rpart",
        control = rpart.control(minsplit = 2),
        tuneGrid = data.frame(cp = 0.01))
fit
```

```{r}
# Plotting the model
rpart.plot(fit$finalModel, extra = 2)
```

# Class Imbalance

```{r}
library(rpart)
library(rpart.plot)
data(Zoo, package="mlbench")
```

```{r}
# Plotting the class distribution
ggplot(Zoo, aes(y = type)) + geom_bar()
```

```{r}
# Changing the class variable to make it into a binary reptile/no reptile classification problem
Zoo_reptile <- Zoo |> 
  mutate(type = factor(Zoo$type == "reptile", 
                       levels = c(FALSE, TRUE),
                       labels = c("nonreptile", "reptile")))
```

```{r}
summary(Zoo_reptile)
```

```{r}
# See if we have a class imbalance problem.

ggplot(Zoo_reptile, aes(y = type)) + geom_bar()
```

```{r}
# Create test and training data
set.seed(1234)

inTrain <- createDataPartition(y = Zoo_reptile$type, p = .5, list = FALSE)
training_reptile <- Zoo_reptile |> slice(inTrain)
testing_reptile <- Zoo_reptile |> slice(-inTrain)
```

## Option 1: Use the Data As Is and Hope For The Best

```{r}
fit <- training_reptile |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        trControl = trainControl(method = "cv"))
```

```{r}
fit
```

```{r}
# Plotting the model
rpart.plot(fit$finalModel, extra = 2)
```

```{r}
# Creating a confusion matrix
confusionMatrix(data = predict(fit, testing_reptile),
                ref = testing_reptile$type, positive = "reptile")
```

## Option 2: Balance Data With Resampling

```{r}
# Using stratified sampling with replacement
library(sampling)
set.seed(1000) # for repeatability

id <- strata(training_reptile, stratanames = "type", size = c(50, 50), method = "srswr")
training_reptile_balanced <- training_reptile |> 
  slice(id$ID_unit)
table(training_reptile_balanced$type)
```

```{r}
fit <- training_reptile_balanced |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        trControl = trainControl(method = "cv"),
        control = rpart.control(minsplit = 5))

fit
```

```{r}
# Plotting the final model
rpart.plot(fit$finalModel, extra = 2)
```

```{r}
# Check on the unbalanced testing data

confusionMatrix(data = predict(fit, testing_reptile),
                ref = testing_reptile$type, positive = "reptile")
```

```{r}
# Analyzing the tradeoff between sensitivity and specificity
id <- strata(training_reptile, stratanames = "type", size = c(50, 100), method = "srswr")
training_reptile_balanced <- training_reptile |> 
  slice(id$ID_unit)
table(training_reptile_balanced$type)
```

```{r}
fit <- training_reptile_balanced |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        trControl = trainControl(method = "cv"),
        control = rpart.control(minsplit = 5))

confusionMatrix(data = predict(fit, testing_reptile),
                ref = testing_reptile$type, positive = "reptile")
```
## Option 3: Build A Larger Tree with Predicted Probabilities

```{r}
# Using AUC as the tuning metric
fit <- training_reptile |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        tuneLength = 10,
        trControl = trainControl(method = "cv",
        classProbs = TRUE,  
        summaryFunction=twoClassSummary),  
        metric = "ROC",
        control = rpart.control(minsplit = 3))
```

```{r}
fit
```

```{r}
# Plotting the model
rpart.plot(fit$finalModel, extra = 2)
```

```{r}
confusionMatrix(data = predict(fit, testing_reptile),
                ref = testing_reptile$type, positive = "reptile")
```

```{r}
# Create A Biased Classifier

prob <- predict(fit, testing_reptile, type = "prob")
tail(prob)
```

```{r}
pred <- as.factor(ifelse(prob[,"reptile"]>=0.01, "reptile", "nonreptile"))

confusionMatrix(data = pred,
                ref = testing_reptile$type, positive = "reptile")
```

```{r}
# Plotting the ROC Curve
library("pROC")
r <- roc(testing_reptile$type == "reptile", prob[,"reptile"])
```

```{r}
r
```

```{r}
# Plott
ggroc(r) + geom_abline(intercept = 1, slope = 1, color = "darkgrey")
```
## Option 4: Use a Cost-Sensitive Classifier

```{r}
# Using a cost matrix
cost <- matrix(c(
  0,   1,
  100, 0
), byrow = TRUE, nrow = 2)
cost
```

```{r}
fit <- training_reptile |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        parms = list(loss = cost),
        trControl = trainControl(method = "cv"))
```

```{r}
fit
```

```{r}
# Plot
rpart.plot(fit$finalModel, extra = 2)
```

```{r}
# Confusion matrix
confusionMatrix(data = predict(fit, testing_reptile),
                ref = testing_reptile$type, positive = "reptile")
```

